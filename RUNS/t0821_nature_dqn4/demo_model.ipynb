{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import gym\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from sklearn.manifold import TSNE\n",
    "from dqn_model import DQN\n",
    "from dqn_learn import OptimiserSpec, dqn_learning\n",
    "from dqn_utils.mygym import get_env\n",
    "from dqn_utils.atari_wrapper import wrap_deepmind\n",
    "from dqn_utils.replaybuffer import ReplayBuffer\n",
    "from dqn_utils.evaluation import *\n",
    "from collections import namedtuple\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "FloatTensor = torch.cuda.FloatTensor if USE_CUDA else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "import time\n",
    "\n",
    "GAME_ID_PONG = 3\n",
    "benchmark = gym.benchmark_spec('Atari40M')\n",
    "task = benchmark.tasks[GAME_ID_PONG]\n",
    "seed = 0\n",
    "env = get_env(task, seed)\n",
    "\n",
    "# - memory\n",
    "replay_buffer_size = 1000000\n",
    "frame_history_len = 4\n",
    "img_h, img_w, img_c = env.observation_space.shape\n",
    "input_arg = frame_history_len * img_c  # in_channels = #.frame-history * channels per frame\n",
    "num_actions = env.action_space.n\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size, frame_history_len)\n",
    "\n",
    "# - model\n",
    "Q = DQN(input_arg, num_actions).type(FloatTensor)\n",
    "Q.load('checkpoints/cp7390000.torchmodel')\n",
    "\n",
    "# - policy\n",
    "def select_greedy_action(model, s):\n",
    "    s_ = torch.from_numpy(s).type(FloatTensor).unsqueeze(0) / 255.0\n",
    "    # unsqueeze(0) => to make the observation a one-sample batch\n",
    "    predicted_action_values = model(Variable(s_, volatile=True)).data  # type: torch.FloatTensor\n",
    "    greedy_action = predicted_action_values.max(dim=1)[1].cpu()\n",
    "    # the 2nd return val of max is the index of the max (argmax) in each row (since\n",
    "        # we have specified dim=1 in the function call)\n",
    "    return greedy_action, predicted_action_values\n",
    "\n",
    "last_obs = env.reset()\n",
    "t = 0\n",
    "\n",
    "rr = 0\n",
    "while t in range(1000):\n",
    "    replay_buffer.store_frame(last_obs)\n",
    "    recent_observations = replay_buffer.encode_recent_observation()\n",
    "    action, action_values = select_greedy_action(Q, recent_observations)\n",
    "    action = action[0, 0]\n",
    "    action_values = action_values.cpu().numpy()\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    last_obs = obs\n",
    "    if done:\n",
    "        break\n",
    "    #env.render()\n",
    "    rr += reward\n",
    "    print \"\\r {}: {:.2f}\".format(t, rr),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-29 09:05:52,833] Making new env: SpaceInvadersNoFrameskip-v4\n",
      "[2017-08-29 09:05:53,111] Finished writing results. You can upload them to the scoreboard via gym.upload('/home/junli/projects/dplay/RUNS/t0821_nature_dqn4/tmp/gym-results')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/SpaceInvadersNoFrameskip-v4/cp9000000\n",
      "ffmpeg -y -framerate 10 -i /home/junli/projects/dplay/RUNS/t0821_nature_dqn4/tmp/SpaceInvadersNoFrameskip-v4/cp9000000/f_%05d.png -c:v libx264 -pix_fmt yuv420p /home/junli/projects/dplay/RUNS/t0821_nature_dqn4/tmp/SpaceInvadersNoFrameskip-v4/cp9000000/out.mp4\n"
     ]
    }
   ],
   "source": [
    "# Init the game environment\n",
    "GAME_ID_PONG = 6\n",
    "benchmark = gym.benchmark_spec('Atari40M')\n",
    "task = benchmark.tasks[GAME_ID_PONG]\n",
    "seed = 0\n",
    "env = get_env(task, seed)\n",
    "#env = gym.make(task.env_id)\n",
    "#env = wrap_deepmind(env)\n",
    "## env = wrappers.Monitor(env, 'tmp/evaluation-monitor', force=True)\n",
    "\n",
    "# prepare demo output\n",
    "PLOT_FEATURE = True\n",
    "trained_model_fname = 'checkpoints_alieninvader/cp9000000.torchmodel'\n",
    "cpfname = os.path.split(os.path.splitext(trained_model_fname)[0])[1]\n",
    "output_image_prefix = 'tmp/{}/{}/f'.format(task.env_id, cpfname)\n",
    "output_image_dir = os.path.split(output_image_prefix)[0]\n",
    "print output_image_dir\n",
    "if not os.path.exists(output_image_dir):\n",
    "    os.makedirs(output_image_dir)\n",
    "ffmpeg_cmd = \"ffmpeg -y -framerate 10 -i {}_%05d.png -c:v \" \\\n",
    "    \"libx264 -pix_fmt yuv420p {}/out.mp4\".format(\n",
    "        os.path.abspath(output_image_prefix),\n",
    "        os.path.abspath(output_image_dir))\n",
    "print ffmpeg_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print env.action_space.contains(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTION meanings\n",
    "import time\n",
    "EXPLORE_ACTION = False\n",
    "if EXPLORE_ACTION:\n",
    "    actions = [0, 0, 0, 2, 2, 2, 5, 5, 5, 4, 4, 4]\n",
    "    env = gym.make(task.env_id)\n",
    "    env.reset()\n",
    "    for A in actions:\n",
    "        for i in range(100):\n",
    "            env.step(A)\n",
    "            env.render()\n",
    "            time.sleep(0.02)\n",
    "            print \"\\r\", A,\n",
    "# Pong    \n",
    "# action_labels = ['NOOP', 'NOOP', 'UP', 'DOWN', 'UP', 'DOWN']\n",
    "# SpaceInvader\n",
    "action_labels = ['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'R+F', 'L+F']\n",
    "#action_labels = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make model\n",
    "# - game configurations\n",
    "frame_history_len = 4\n",
    "max_evaluation_steps = 10000\n",
    "replay_buffer_size = 1000000 # not training, just for the frame-encoding function\n",
    "\n",
    "# - init model parameters (derived)\n",
    "img_h, img_w, img_c = env.observation_space.shape\n",
    "input_arg = frame_history_len * img_c  # in_channels = #.frame-history * channels per frame\n",
    "num_actions = env.action_space.n\n",
    "replay_buffer = ReplayBuffer(replay_buffer_size, frame_history_len)\n",
    "\n",
    "# - greedy policy\n",
    "def select_greedy_action(model, s):\n",
    "    s_ = torch.from_numpy(s).type(FloatTensor).unsqueeze(0) / 255.0\n",
    "    # unsqueeze(0) => to make the observation a one-sample batch\n",
    "    predicted_action_values = model(Variable(s_, volatile=True)).data  # type: torch.FloatTensor\n",
    "    greedy_action = predicted_action_values.max(dim=1)[1].cpu()\n",
    "    # the 2nd return val of max is the index of the max (argmax) in each row (since\n",
    "        # we have specified dim=1 in the function call)\n",
    "    return greedy_action, predicted_action_values\n",
    "    \n",
    "collector_hook = FeatureCollector()\n",
    "Q = DQN(input_arg, num_actions).type(FloatTensor)\n",
    "if os.path.exists(trained_model_fname):\n",
    "    Q.load(trained_model_fname)\n",
    "else:\n",
    "    print \"No such file!!\"\n",
    "if PLOT_FEATURE:\n",
    "    tmp_mod_list = [m for m in Q.modules()]\n",
    "    fc5 = tmp_mod_list[-1] # get the last forward layer\n",
    "    fc5.register_forward_hook(collector_hook)\n",
    "\n",
    "\n",
    "# Test cell, see if the first step can run\n",
    "TEST_STEP = False\n",
    "if TEST_STEP:\n",
    "    last_obs = env.reset()\n",
    "    replay_buffer.store_frame(last_obs)\n",
    "    recent_observations = replay_buffer.encode_recent_observation()\n",
    "    action, action_values = select_greedy_action(Q, recent_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-29 09:06:00,329] Starting new video recorder writing to /home/junli/projects/dplay/RUNS/t0821_nature_dqn4/tmp/gym-results/openaigym.video.1.24018.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1580: 70.00                      \n"
     ]
    }
   ],
   "source": [
    "# Run the game and collect all we needed.\n",
    "last_obs = env.reset()\n",
    "t = 0\n",
    "rec = EvaluationRecord(\n",
    "    observations = [],\n",
    "    final_features = collector_hook.data,\n",
    "    predicted_action_values = [],\n",
    "    actions = []\n",
    ")\n",
    "\n",
    "rr=0\n",
    "for t in range(max_evaluation_steps):\n",
    "    replay_buffer.store_frame(last_obs)\n",
    "    recent_observations = replay_buffer.encode_recent_observation()\n",
    "    action, action_values = select_greedy_action(Q, recent_observations)\n",
    "    action = action[0, 0]\n",
    "    action_values = action_values.cpu().numpy()\n",
    "    rec.observations.append(recent_observations)\n",
    "    rec.predicted_action_values.append(action_values)\n",
    "    rec.actions.append(action)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    last_obs = obs\n",
    "    if done:\n",
    "        break\n",
    "    rr += reward\n",
    "    print \"\\r {}: {:.2f}\".format(t, rr),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if PLOT_FEATURE:\n",
    "    tsne = TSNE()\n",
    "    feat2d = tsne.fit_transform(np.vstack(rec.hidden_features))\n",
    "else:\n",
    "    feat2d = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T=1581                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n"
     ]
    }
   ],
   "source": [
    "draw_state_evaluation(rec, feat2d, output_image_prefix,\n",
    "    action_labels=action_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
